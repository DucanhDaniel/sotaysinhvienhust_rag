{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git  clone  https://huggingface.co/dangtr0408/StyleTTS2-lite-vi\n",
        "%cd  StyleTTS2-lite-vi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l60C8R64Ue8i",
        "outputId": "6605f5b2-b0b1-4df7-b5af-934b4e103410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'StyleTTS2-lite-vi'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 108 (delta 44), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Receiving objects: 100% (108/108), 6.21 MiB | 12.09 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip  install  -r  requirements.txt"
      ],
      "metadata": {
        "id": "JFtwVO3BUhqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from inference import StyleTTS2\n",
        "\n",
        "import librosa\n",
        "import IPython.display as ipd\n",
        "import torch.cuda\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "azamtCMkUowB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_path = \"Models/config.yaml\"\n",
        "models_path = \"Models/base_model_120k_vi.pth\""
      ],
      "metadata": {
        "id": "3BX-wZlOVBiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speakers = {\n",
        "    \"id_1\": {\n",
        "        \"path\": \"./reference_audio/vn_1.wav\",   #Ref audio path\n",
        "        \"lang\": \"vi\",                           #Default language\n",
        "        \"speed\": 1.0,                           #Speaking speed\n",
        "    },\n",
        "    \"id_2\": {\n",
        "        \"path\": \"./reference_audio/vn_2.wav\",\n",
        "        \"lang\": \"vi\",\n",
        "        \"speed\": 1.0,\n",
        "    },\n",
        "    \"id_3\": {\n",
        "        \"path\": \"./reference_audio/vn_3.wav\",\n",
        "        \"lang\": \"vi\",\n",
        "        \"speed\": 1.0,\n",
        "    },\n",
        "    \"id_4\": {\n",
        "        \"path\": \"./reference_audio/vn_4.wav\",\n",
        "        \"lang\": \"vi\",\n",
        "        \"speed\": 1.0,\n",
        "    },\n",
        "}\n",
        "for id in speakers:\n",
        "    max_samples = 24000*20 #max 20 seconds ref audio\n",
        "    print(speakers[id]['path'])\n",
        "    wave, sr = librosa.load(speakers[id]['path'], sr=24000)\n",
        "    audio, index = librosa.effects.trim(wave, top_db=30)\n",
        "    if sr != 24000:              audio = librosa.resample(audio, sr, 24000)\n",
        "    if len(audio) > max_samples: audio = audio[:max_samples]\n",
        "    display(ipd.Audio(audio, rate=24000, normalize=True))"
      ],
      "metadata": {
        "id": "_1WTsvnCVD5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model             = StyleTTS2(config_path, models_path).eval().to(device)\n",
        "default_speaker   = \"[id_1]\"  #STR    Default speaker used when no speaker_id is provided in the input\n",
        "avg_style         = True      #BOOL   Split the ref audio and calculate the avg styles.\n",
        "stabilize         = True      #BOOL   Stabilize speaking speed.\n",
        "denoise           = 0.6       #FLOAT  Adjust the strength of the denoiser. Value range is [0, 1]\n",
        "n_merge           = 18        #INT    Avoid short sentences by merging when a sentence has fewer than n words"
      ],
      "metadata": {
        "id": "bT6e6HpgVcXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install espeak-ng"
      ],
      "metadata": {
        "id": "z6JM1EcHWA-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "[id_1]Quãng thời gian đi học là một trong những ký ức đẹp nhất trong cuộc đời mỗi con người. Mỗi mùa khai giảng là một dấu mốc đặc biệt, luôn là dịp được nhiều sinh viên mong đợi. Hàng năm, cứ vào dịp tháng 9, 10 là sinh viên Đại học Bách khoa Hà Nội lại nô nức tham dự Lễ khai giảng, mang theo niềm vui, hi vọng về một năm học mới. Ngày khai giảng năm học mới luôn rất ý nghĩa và được mong đợi đối với các em tân sinh viên.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mA1DwKUbXYdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    styles = model.get_styles(speakers, denoise, avg_style)\n",
        "    r = model.generate(text, styles, stabilize, n_merge, default_speaker)\n",
        "\n",
        "print('Synthesized:')\n",
        "display(ipd.Audio(r, rate=24000, normalize=True))"
      ],
      "metadata": {
        "id": "fC8BEIHGVsoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cài đặt các thư viện cho server API\n",
        "!pip install fastapi \"uvicorn[standard]\" pyngrok python-multipart --quiet\n",
        "\n",
        "print(\"Cài đặt môi trường hoàn tất.\")\n",
        "print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "LkMJGa2OrokI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uvicorn\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.responses import Response\n",
        "from pydantic import BaseModel\n",
        "from pyngrok import ngrok, conf\n",
        "import threading\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import soundfile as sf\n",
        "from io import BytesIO\n",
        "\n",
        "\n",
        "# --- CẤU HÌNH NGROK ---\n",
        "NGROK_AUTHTOKEN = \"2tWsdY4JT9nt2pWbQnQpEPN4hEp_4p8KQCHZ45JrDMpaRnKo4\"\n",
        "conf.get_default().auth_token = NGROK_AUTHTOKEN\n",
        "\n",
        "# --- KHỞI TẠO FASTAPI APP ---\n",
        "app = FastAPI()\n",
        "\n",
        "# Định nghĩa cấu trúc dữ liệu cho request, thêm speaker_id\n",
        "class TTSRequest(BaseModel):\n",
        "    text: str\n",
        "    speaker_id: int = 1 # Giọng đọc mặc định là 1\n",
        "\n",
        "@app.get(\"/\", summary=\"Endpoint gốc để kiểm tra server\")\n",
        "def read_root():\n",
        "    return {\"message\": \"Server VietVoice-TTS đang hoạt động!\"}\n",
        "\n",
        "@app.post(\"/tts\", summary=\"Tổng hợp văn bản thành giọng nói\")\n",
        "async def text_to_speech(request: TTSRequest):\n",
        "    \"\"\"\n",
        "    Nhận văn bản và ID giọng đọc, tạo ra audio và trả về trực tiếp.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"Nhận yêu cầu: text='{request.text}', speaker_id={request.speaker_id}\")\n",
        "\n",
        "        # 1. Định dạng lại văn bản với ID giọng đọc\n",
        "        formatted_text = f\"[id_{request.speaker_id}]{request.text}\"\n",
        "\n",
        "        # 2. Gọi model để sinh audio (dữ liệu thô dạng NumPy array)\n",
        "        with torch.no_grad():\n",
        "            # Các tham số này có thể được tùy chỉnh nếu cần\n",
        "            audio_data = model.generate(formatted_text, styles, stabilize, n_merge, default_speaker)\n",
        "\n",
        "        # 3. Chuyển đổi dữ liệu audio thô thành file WAV trong bộ nhớ\n",
        "        byte_io = BytesIO()\n",
        "        sf.write(byte_io, audio_data, samplerate=24000, format='WAV')\n",
        "        wav_bytes = byte_io.getvalue()\n",
        "\n",
        "        # 4. Trả về dữ liệu WAV bytes trực tiếp trong response\n",
        "        return Response(content=wav_bytes, media_type=\"audio/wav\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi trong quá trình tổng hợp: {e}\")\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "def run_app():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "ngrok.kill()\n",
        "server_thread = threading.Thread(target=run_app)\n",
        "server_thread.start()\n",
        "time.sleep(5)\n",
        "try:\n",
        "    public_url = ngrok.connect(8000)\n",
        "    print(\"\\n\" + \"=\"*55)\n",
        "    print(\"FastAPI TTS Server đã được khởi chạy thành công!\")\n",
        "    print(f\"URL công khai: {public_url}\")\n",
        "    print(\"Gửi yêu cầu POST tới endpoint: \" + f\"{public_url}/tts\")\n",
        "    print('Ví dụ payload: {\"text\": \"xin chào\", \"speaker_id\": 1}')\n",
        "    print(\"=\"*55)\n",
        "except Exception as e:\n",
        "    print(f\"\\n Lỗi khi kết nối ngrok: {e}\")"
      ],
      "metadata": {
        "id": "J2Md5wC9oiSy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}